import spark.implicits._
  
val data = Seq(
    ("Stock", "Plus500", 0.5938, "Amazon", "01/11/2021", 3368.000, 4000.0),
 ("Stock", "Plus500", 0.6, "Facebook", "01/11/2021", 160.0, 200.0),
 ("Stock", "Plus500", 0.68, "Amazon", "01/11/2021", 160.0, 200.0),
 ("Stock", "eToro", 1.5, "Facebook", "12/11/2021", 180.0, 250.0),
 ("Stock", "Plus500", 0.065, "LinkedIn", "12/11/2021", 80.0, 140.0),
 ("Stock", "eToro", 1.3, "Pfeizer", "01/12/2021", 34.0, 85.5),
 ("Stock", "Plus500", 0.01, "Bitcoin", "01/11/2021", 45000.0, 48000.0),
 ("Stock", "Plus500", 0.08, "Sand", "29/11/2021", 5.4, 8.9)
    )

val firstApproachDF = data.toDF("Asset", "Platform", "Unit", "Trade Name", "Buy Date", "Buy Price", "Sell Price")

firstApproachDF.show()

firstApproachDF.printSchema 
firstApproachDF.columns.map(col => col + "_suffix")

firstApproachDF.selectExpr("Asset", "Platform", """`Trade Name`""", """`Buy Date`""", 
"Unit", """ `Sell Price` - `Buy Price` as profit""" ).show(5)

firstApproachDF.filter(col("Platform") === "Plus500").show()

val orExampleDF = firstApproachDF.filter(col("Trade Name") === "Amazon" 
|| col("Trade Name") ==="Facebook")

orExampleDF.show()

val numberOfTradesPerPlatform = firstApproachDF.groupBy("Asset", "Platform")
.agg(count("*").as("NumberOfTradesPerAssetPPlatForm"))

numberOfTradesPerPlatform.show()
